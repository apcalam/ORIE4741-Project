{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
      "######################################################################### 100.0%\n",
      "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1mNo Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.5/Project.toml`\n",
      "\u001b[32m\u001b[1mNo Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.5/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.add(\"ProgressBars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Plots.PyPlotBackend()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Random, LinearAlgebra, Plots\n",
    "# bring packages into main namespace\n",
    "using DataFrames             # Data tables are called \"DataFrames\"\n",
    "using StatsPlots             # load plotting packages \n",
    "using Statistics             # basic statistical functions\n",
    "using CSV                    # tools for working with CSV files\n",
    "using Plots, Random, LinearAlgebra, Statistics, SparseArrays\n",
    "using ProgressBars\n",
    "include(\"proxgrad.jl\")\n",
    "pyplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(n_train, n_test) = (181253, 20139)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>tbl</th><th>Year</th><th>quarter</th><th>citymarketid_1</th><th>citymarketid_2</th><th>city1</th></tr><tr><th></th><th>String</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>String</th></tr></thead><tbody><p>6 rows × 24 columns (omitted printing of 18 columns)</p><tr><th>1</th><td>Table 1a</td><td>2010</td><td>1</td><td>34614</td><td>33195</td><td>Salt Lake City, UT</td></tr><tr><th>2</th><td>Table 1a</td><td>1998</td><td>4</td><td>30189</td><td>31703</td><td>Colorado Springs, CO</td></tr><tr><th>3</th><td>Table 1a</td><td>1998</td><td>4</td><td>30198</td><td>30852</td><td>Pittsburgh, PA</td></tr><tr><th>4</th><td>Table 1a</td><td>2009</td><td>3</td><td>32211</td><td>32575</td><td>Las Vegas, NV</td></tr><tr><th>5</th><td>Table 1a</td><td>1993</td><td>4</td><td>30255</td><td>30852</td><td>Huntsville, AL</td></tr><tr><th>6</th><td>Table 1a</td><td>2010</td><td>4</td><td>33198</td><td>32575</td><td>Kansas City, MO</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& tbl & Year & quarter & citymarketid\\_1 & citymarketid\\_2 & city1 & \\\\\n",
       "\t\\hline\n",
       "\t& String & Int64 & Int64 & Int64 & Int64 & String & \\\\\n",
       "\t\\hline\n",
       "\t1 & Table 1a & 2010 & 1 & 34614 & 33195 & Salt Lake City, UT & $\\dots$ \\\\\n",
       "\t2 & Table 1a & 1998 & 4 & 30189 & 31703 & Colorado Springs, CO & $\\dots$ \\\\\n",
       "\t3 & Table 1a & 1998 & 4 & 30198 & 30852 & Pittsburgh, PA & $\\dots$ \\\\\n",
       "\t4 & Table 1a & 2009 & 3 & 32211 & 32575 & Las Vegas, NV & $\\dots$ \\\\\n",
       "\t5 & Table 1a & 1993 & 4 & 30255 & 30852 & Huntsville, AL & $\\dots$ \\\\\n",
       "\t6 & Table 1a & 2010 & 4 & 33198 & 32575 & Kansas City, MO & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "6×24 DataFrame. Omitted printing of 19 columns\n",
       "│ Row │ tbl      │ Year  │ quarter │ citymarketid_1 │ citymarketid_2 │\n",
       "│     │ \u001b[90mString\u001b[39m   │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m   │ \u001b[90mInt64\u001b[39m          │ \u001b[90mInt64\u001b[39m          │\n",
       "├─────┼──────────┼───────┼─────────┼────────────────┼────────────────┤\n",
       "│ 1   │ Table 1a │ 2010  │ 1       │ 34614          │ 33195          │\n",
       "│ 2   │ Table 1a │ 1998  │ 4       │ 30189          │ 31703          │\n",
       "│ 3   │ Table 1a │ 1998  │ 4       │ 30198          │ 30852          │\n",
       "│ 4   │ Table 1a │ 2009  │ 3       │ 32211          │ 32575          │\n",
       "│ 5   │ Table 1a │ 1993  │ 4       │ 30255          │ 30852          │\n",
       "│ 6   │ Table 1a │ 2010  │ 4       │ 33198          │ 32575          │"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = CSV.read(\"Consumer_Airfare_Report__Table_1a_-_All_U.S._Airport_Pair_Markets.csv\")\n",
    "dataset = dropmissing(dataset)\n",
    "dataset[:when] = dataset[:Year] .+ ((dataset[:quarter] .-1) ./ 4)\n",
    "n = size(dataset,1)\n",
    "r = .1\n",
    "cuttoff = Int(round(n*r))\n",
    "idxs = rand(1:n,n)\n",
    "\n",
    "# We need to hold out a test dataset to report final results on, that is not used at all for model selection.\n",
    "# Within k-fold cross validation, train and val datasets will be formed from this main train dataset. \n",
    "test_dataset  = dataset[idxs[1:cuttoff],:]\n",
    "train_dataset = dataset[idxs[cuttoff+1:n],:]\n",
    "\n",
    "n_train = size(train_dataset,1)\n",
    "n_test = size(test_dataset,1)\n",
    "\n",
    "@assert  n_train + n_test == n\n",
    "@show n_train, n_test\n",
    "head(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test_models (generic function with 2 methods)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do k-fold cross validation and return the average error_metric on the validation set accross the k folds.\n",
    "function cross_val(featurizer, loss, regularizer, stepsize, error_metric; k=10, dataset=train_dataset)\n",
    "    X,y = featurizer(dataset)\n",
    "    n = size(dataset,1)\n",
    "    r = Int(round(n / k))\n",
    "    idxs = rand(1:n,n) # to shuffle the dataset\n",
    "    error = 0\n",
    "    for i in tqdm(1:k)\n",
    "        val_idxs = r*(i-1)+1:min(r*i,n)\n",
    "        tr_low = 1:r*(i-1)\n",
    "        tr_high = r*i+1:n\n",
    "        if (i == 1)\n",
    "            tr_idxs = tr_high\n",
    "        elseif (i == k)\n",
    "            tr_idxs = tr_low\n",
    "        else\n",
    "            tr_idxs = [tr_low ; tr_high ]\n",
    "        end\n",
    "        # @show i, val_idxs\n",
    "        # @show tr_low, tr_high\n",
    "        X_tr = X[idxs[tr_idxs],:]\n",
    "        y_tr = y[idxs[tr_idxs]]\n",
    "        \n",
    "        X_val = X[idxs[val_idxs],:]\n",
    "        y_val = y[idxs[val_idxs]]\n",
    "        \n",
    "        w = proxgrad(loss, regularizer, X_tr, y_tr; stepsize=stepsize) \n",
    "        ŷ_val = X_val * w\n",
    "        # @show size(y_val)\n",
    "        # @show size(ŷ_val)\n",
    "        error += error_metric(ŷ_val, y_val)\n",
    "    end\n",
    "    return error / k\n",
    "end\n",
    "\n",
    "function extrapolation_val(featurizer, loss, regularizer, stepsize, error_metric; k=10, dataset=train_dataset)\n",
    "    X,y = featurizer(dataset)\n",
    "    n = size(X,1)\n",
    "    \n",
    "    tr_idxs = dataset[:when].< 2013.5\n",
    "    val_idxs = dataset[:when].>= 2013.5\n",
    "    \n",
    "    X_tr = X[tr_idxs,:]\n",
    "    y_tr = y[tr_idxs]\n",
    "    n_tr = size(X_tr,1)\n",
    "\n",
    "    X_val = X[val_idxs,:]\n",
    "    y_val = y[val_idxs]\n",
    "    n_val = size(X_val,1)\n",
    "    \n",
    "    @assert n_tr + n_val == n\n",
    "\n",
    "    w = proxgrad(loss, regularizer, X_tr, y_tr; stepsize=stepsize) \n",
    "    ŷ_val = X_val * w\n",
    "    # @show size(y_val)\n",
    "    # @show size(ŷ_val)\n",
    "    \n",
    "    return error_metric(ŷ_val, y_val)\n",
    "end\n",
    "\n",
    "function train_and_validate(featurizer, loss, regularizer, stepsize, error_metric, mode; k=10, dataset=train_dataset)\n",
    "    if (mode==\"interpolation\")\n",
    "        return cross_val(featurizer, loss, regularizer, stepsize, error_metric; k=k, dataset=dataset)\n",
    "    else\n",
    "        return extrapolation_val(featurizer, loss, regularizer, stepsize, error_metric; k=k, dataset=dataset)\n",
    "    end\n",
    "end\n",
    "\n",
    "# For each model in models, do k-fold cross validation and calculate the average error_metric\n",
    "# on the val set accross the k-folds.\n",
    "# Each model in model is a tuple of the form (featurizer, loss, regularizer, stepsize),\n",
    "# where a featurizer is a funciton that takes in a dataset and returns X,y. \n",
    "# Returns errors for each model, and the index of the best model\n",
    "function test_models(models, error_metric,mode;k=10, dataset=train_dataset)\n",
    "    errors = []\n",
    "    for model in models\n",
    "        error = train_and_validate(model...,error_metric,mode;k=k,dataset=dataset)\n",
    "        errors = [errors; error]\n",
    "    end\n",
    "    i = argmin(errors)\n",
    "    println(\"The best model is model \",i)\n",
    "    return errors,i\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "onehot"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_labels = [:carrier_lg, :carrier_low, :airportid_1, :airportid_2]\n",
    "cat_labels_sub = [:carrier_lg, :carrier_low]\n",
    "\n",
    "#Sets of all categories in a particular column\n",
    "cats_sets = [unique(dataset[:, label]) for label in cat_labels]\n",
    "cats_sets_sub = [unique(dataset[:, label]) for label in cat_labels_sub]\n",
    "\n",
    "\"Computes a onehot vector for every entry in column given a set of categories cats\"\n",
    "function onehot(column, cats=unique(column))\n",
    "    result = zeros(length(column), length(cats))\n",
    "    for i = 1:length(column)\n",
    "        for j =1:length(cats)\n",
    "            if column[i] === cats[j]\n",
    "                result[i, j] = 1\n",
    "            end    \n",
    "        end\n",
    "    end\n",
    "    result\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7-element Array{Symbol,1}:\n",
       " :when\n",
       " :nsmiles\n",
       " :passengers\n",
       " :large_ms\n",
       " :fare_lg\n",
       " :lf_ms\n",
       " :fare_low"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_real = [\n",
    "    :when, \n",
    "    :citymarketid_1, \n",
    "    :citymarketid_2,\n",
    "    :airportid_1,\n",
    "    :airportid_2,\n",
    "    :nsmiles,\n",
    "    :passengers,\n",
    "    :large_ms,\n",
    "    :fare_lg,\n",
    "    :lf_ms,\n",
    "    :fare_low\n",
    "]\n",
    "labels_real_sub = [\n",
    "    :when, \n",
    "    :nsmiles,\n",
    "    :passengers,\n",
    "    :large_ms,\n",
    "    :fare_lg,\n",
    "    :lf_ms,\n",
    "    :fare_low\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0%┣██████████████████████████████████████████┫ 15/15 [04:54<00:00, 0.0 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [04:40<00:00, 0.0 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [04:24<00:00, 0.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [04:20<00:00, 0.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [04:36<00:00, 0.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [04:19<00:00, 0.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [04:47<00:00, 0.0 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [05:05<00:00, 0.0 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [04:45<00:00, 0.0 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [04:58<00:00, 0.0 it/s]┣██████████████▊                             ┫ 5/15 [01:38<04:04, 0.0 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [05:12<00:00, 0.0 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [04:51<00:00, 0.0 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [05:28<00:00, 0.0 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [04:28<00:00, 0.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [04:18<00:00, 0.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [04:53<00:00, 0.0 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [04:22<00:00, 0.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [04:51<00:00, 0.0 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [04:24<00:00, 0.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [04:04<00:00, 0.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [04:37<00:00, 0.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [04:20<00:00, 0.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [04:27<00:00, 0.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [05:37<00:00, 0.0 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [05:38<00:00, 0.0 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [05:09<00:00, 0.0 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [06:09<00:00, 0.0 it/s]\n",
      "The best model is model 21\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Any[3298.7706837318037, 3344.9843398703783, 3349.547505428101, 3329.4232726401665, 3316.731939845658, 3303.3380665669542, 2917.3447900504098, 2903.5253012967105, 2915.027215413823, 3332.8733037672127  …  2910.890427014236, 2713.335204303255, 2742.71220470165, 2710.8933066291024, 3317.7050081519506, 3316.4787825887965, 3329.23706083248, 3200.206009948353, 3208.812632015834, 3201.029026980858], 21)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline featurizer\n",
    "function feats_0(dataset)\n",
    "    X = [dataset[:when] dataset[:airportid_1] dataset[:airportid_2] ones(size(dataset,1))]\n",
    "    y = dataset[:fare]\n",
    "    return X,y\n",
    "end\n",
    "\n",
    "# Only numeric features (treating airportid and cityid as numeric)\n",
    "function feats_1(dataset)\n",
    "    real_vals = convert(Matrix, dataset[labels_real])\n",
    "    X = hcat(real_vals, ones(size(dataset,1)))\n",
    "    y = dataset[:fare]\n",
    "    return X,y\n",
    "end\n",
    "\n",
    "# Numeric and categorical combined (treating airportid and cityid as numerical)\n",
    "function feats_2(dataset)\n",
    "    real_vals = convert(Matrix, dataset[labels_real])\n",
    "    cat_vals = hcat([onehot(dataset[:, cat_labels_sub[i]], cats_sets_sub[i]) for i in 1:size(cat_labels_sub, 1)]...)\n",
    "    X = hcat(cat_vals, real_vals, ones(size(dataset,1)))\n",
    "    y = dataset[:fare]\n",
    "    return X,y\n",
    "end\n",
    "\n",
    "# Numeric and categorical combined (treating airportid and cityid as categorical)\n",
    "function feats_3(dataset)\n",
    "    real_vals = convert(Matrix, dataset[labels_real_sub])\n",
    "    cat_vals = hcat([onehot(dataset[:, cat_labels[i]], cats_sets[i]) for i in 1:size(cat_labels, 1)]...)\n",
    "    X = hcat(cat_vals, real_vals, ones(size(dataset,1)))\n",
    "    y = dataset[:fare]\n",
    "    return X,y\n",
    "end\n",
    "\n",
    "MSE(L1,L2) = sum((L1.-L2).^2) / size(L1,1)\n",
    "\n",
    "models = [\n",
    "    (feats_3, 1/n_train*QuadLoss(), 0.25*QuadReg(), .1),\n",
    "    (feats_3, 1/n_train*QuadLoss(), 0.5*QuadReg(), .1),\n",
    "    (feats_3, 1/n_train*QuadLoss(), 0.75*QuadReg(), .1),\n",
    "    \n",
    "    (feats_3, 1/n_train*QuadLoss(), 0.25*QuadReg(), .2),\n",
    "    (feats_3, 1/n_train*QuadLoss(), 0.5*QuadReg(), .2),\n",
    "    (feats_3, 1/n_train*QuadLoss(), 0.75*QuadReg(), .2),\n",
    "    \n",
    "    (feats_3, 1/n_train*QuadLoss(), 0.25*QuadReg(), .3),\n",
    "    (feats_3, 1/n_train*QuadLoss(), 0.5*QuadReg(), .3),\n",
    "    (feats_3, 1/n_train*QuadLoss(), 0.75*QuadReg(), .3),\n",
    "    \n",
    "    (feats_3, 1/n_train*QuadLoss(), 0.25*QuadReg(), .4),\n",
    "    (feats_3, 1/n_train*QuadLoss(), 0.5*QuadReg(), .4),\n",
    "    (feats_3, 1/n_train*QuadLoss(), 0.75*QuadReg(), .4),\n",
    "    \n",
    "    (feats_3, 1/n_train*QuadLoss(), 0.25*QuadReg(), .5),\n",
    "    (feats_3, 1/n_train*QuadLoss(), 0.5*QuadReg(), .5),\n",
    "    (feats_3, 1/n_train*QuadLoss(), 0.75*QuadReg(), .5),\n",
    "    \n",
    "    (feats_3, 1/n_train*QuadLoss(), 0.25*QuadReg(), .6),\n",
    "    (feats_3, 1/n_train*QuadLoss(), 0.5*QuadReg(), .6),\n",
    "    (feats_3, 1/n_train*QuadLoss(), 0.75*QuadReg(), .6),\n",
    "    \n",
    "    (feats_3, 1/n_train*QuadLoss(), 0.25*QuadReg(), .7),\n",
    "    (feats_3, 1/n_train*QuadLoss(), 0.5*QuadReg(), .7),\n",
    "    (feats_3, 1/n_train*QuadLoss(), 0.75*QuadReg(), .7),\n",
    "    \n",
    "    (feats_3, 1/n_train*QuadLoss(), 0.25*QuadReg(), .8),\n",
    "    (feats_3, 1/n_train*QuadLoss(), 0.5*QuadReg(), .8),\n",
    "    (feats_3, 1/n_train*QuadLoss(), 0.75*QuadReg(), .8),\n",
    "    \n",
    "    (feats_3, 1/n_train*QuadLoss(), 0.25*QuadReg(), .9),\n",
    "    (feats_3, 1/n_train*QuadLoss(), 0.5*QuadReg(), .9),\n",
    "    (feats_3, 1/n_train*QuadLoss(), 0.75*QuadReg(), .9),\n",
    "]\n",
    "\n",
    "errors,i = test_models(models,MSE,\"interpolation\";k=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.788737289865547"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(train_dataset[:when].< 2013.5) / size(train_dataset,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model is model 25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Any[2780.8342180277473, 2780.841445951628, 2780.848673845701, 2780.8342180277473, 2780.841445951628, 2780.848673845701, 3123.6936048510393, 3123.6983442151018, 3123.7030835652886, 2780.8342180277473  …  3123.7030835652886, 2946.9406577359696, 2946.9466016966185, 2946.9525456360375, 2780.8342180277473, 2780.841445951628, 2780.848673845701, 2633.0134051384034, 2633.021899710596, 2633.030394243823], 25)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call external extrapolation on models\n",
    "errors,i = test_models(models,MSE,\"extrapolation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.5.1",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
