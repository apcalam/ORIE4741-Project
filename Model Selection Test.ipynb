{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
      "######################################################################### 100.0%\n",
      "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  Installed\u001b[22m\u001b[39m ProgressBars ─ v0.7.1\n",
      "\u001b[32m\u001b[1mUpdating\u001b[22m\u001b[39m `~/.julia/environments/v1.5/Project.toml`\n",
      " \u001b[90m [49802e3a] \u001b[39m\u001b[92m+ ProgressBars v0.7.1\u001b[39m\n",
      "\u001b[32m\u001b[1mUpdating\u001b[22m\u001b[39m `~/.julia/environments/v1.5/Manifest.toml`\n",
      " \u001b[90m [49802e3a] \u001b[39m\u001b[92m+ ProgressBars v0.7.1\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.add(\"ProgressBars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling ProgressBars [49802e3a-d2f1-5c88-81d8-b72133a6f568]\n",
      "└ @ Base loading.jl:1278\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Plots.PyPlotBackend()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Random, LinearAlgebra, Plots\n",
    "# bring packages into main namespace\n",
    "using DataFrames             # Data tables are called \"DataFrames\"\n",
    "using StatsPlots             # load plotting packages \n",
    "using Statistics             # basic statistical functions\n",
    "using CSV                    # tools for working with CSV files\n",
    "using Plots, Random, LinearAlgebra, Statistics, SparseArrays\n",
    "using ProgressBars\n",
    "include(\"proxgrad.jl\")\n",
    "pyplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(n_train, n_test) = (181253, 20139)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>tbl</th><th>Year</th><th>quarter</th><th>citymarketid_1</th><th>citymarketid_2</th><th>city1</th></tr><tr><th></th><th>String</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>String</th></tr></thead><tbody><p>6 rows × 24 columns (omitted printing of 18 columns)</p><tr><th>1</th><td>Table 1a</td><td>2010</td><td>1</td><td>34614</td><td>33195</td><td>Salt Lake City, UT</td></tr><tr><th>2</th><td>Table 1a</td><td>1998</td><td>4</td><td>30189</td><td>31703</td><td>Colorado Springs, CO</td></tr><tr><th>3</th><td>Table 1a</td><td>1998</td><td>4</td><td>30198</td><td>30852</td><td>Pittsburgh, PA</td></tr><tr><th>4</th><td>Table 1a</td><td>2009</td><td>3</td><td>32211</td><td>32575</td><td>Las Vegas, NV</td></tr><tr><th>5</th><td>Table 1a</td><td>1993</td><td>4</td><td>30255</td><td>30852</td><td>Huntsville, AL</td></tr><tr><th>6</th><td>Table 1a</td><td>2010</td><td>4</td><td>33198</td><td>32575</td><td>Kansas City, MO</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& tbl & Year & quarter & citymarketid\\_1 & citymarketid\\_2 & city1 & \\\\\n",
       "\t\\hline\n",
       "\t& String & Int64 & Int64 & Int64 & Int64 & String & \\\\\n",
       "\t\\hline\n",
       "\t1 & Table 1a & 2010 & 1 & 34614 & 33195 & Salt Lake City, UT & $\\dots$ \\\\\n",
       "\t2 & Table 1a & 1998 & 4 & 30189 & 31703 & Colorado Springs, CO & $\\dots$ \\\\\n",
       "\t3 & Table 1a & 1998 & 4 & 30198 & 30852 & Pittsburgh, PA & $\\dots$ \\\\\n",
       "\t4 & Table 1a & 2009 & 3 & 32211 & 32575 & Las Vegas, NV & $\\dots$ \\\\\n",
       "\t5 & Table 1a & 1993 & 4 & 30255 & 30852 & Huntsville, AL & $\\dots$ \\\\\n",
       "\t6 & Table 1a & 2010 & 4 & 33198 & 32575 & Kansas City, MO & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "6×24 DataFrame. Omitted printing of 19 columns\n",
       "│ Row │ tbl      │ Year  │ quarter │ citymarketid_1 │ citymarketid_2 │\n",
       "│     │ \u001b[90mString\u001b[39m   │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m   │ \u001b[90mInt64\u001b[39m          │ \u001b[90mInt64\u001b[39m          │\n",
       "├─────┼──────────┼───────┼─────────┼────────────────┼────────────────┤\n",
       "│ 1   │ Table 1a │ 2010  │ 1       │ 34614          │ 33195          │\n",
       "│ 2   │ Table 1a │ 1998  │ 4       │ 30189          │ 31703          │\n",
       "│ 3   │ Table 1a │ 1998  │ 4       │ 30198          │ 30852          │\n",
       "│ 4   │ Table 1a │ 2009  │ 3       │ 32211          │ 32575          │\n",
       "│ 5   │ Table 1a │ 1993  │ 4       │ 30255          │ 30852          │\n",
       "│ 6   │ Table 1a │ 2010  │ 4       │ 33198          │ 32575          │"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = CSV.read(\"Consumer_Airfare_Report__Table_1a_-_All_U.S._Airport_Pair_Markets.csv\")\n",
    "dataset = dropmissing(dataset)\n",
    "dataset[:when] = dataset[:Year] .+ ((dataset[:quarter] .-1) ./ 4)\n",
    "n = size(dataset,1)\n",
    "r = .1\n",
    "cuttoff = Int(round(n*r))\n",
    "idxs = rand(1:n,n)\n",
    "\n",
    "# We need to hold out a test dataset to report final results on, that is not used at all for model selection.\n",
    "# Within k-fold cross validation, train and val datasets will be formed from this main train dataset. \n",
    "test_dataset  = dataset[idxs[1:cuttoff],:]\n",
    "train_dataset = dataset[idxs[cuttoff+1:n],:]\n",
    "\n",
    "n_train = size(train_dataset,1)\n",
    "n_test = size(test_dataset,1)\n",
    "\n",
    "@assert  n_train + n_test == n\n",
    "@show n_train, n_test\n",
    "head(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test_models (generic function with 1 method)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do k-fold cross validation and return the average error_metric on the validation set accross the k folds.\n",
    "function cross_val(featurizer, loss, regularizer, stepsize, error_metric; k=10, dataset=train_dataset)\n",
    "    X,y = featurizer(dataset)\n",
    "    n = size(dataset,1)\n",
    "    r = Int(round(n / k))\n",
    "    idxs = rand(1:n,n) # to shuffle the dataset\n",
    "    error = 0\n",
    "    for i in tqdm(1:k)\n",
    "        val_idxs = r*(i-1)+1:min(r*i,n)\n",
    "        tr_low = 1:r*(i-1)\n",
    "        tr_high = r*i+1:n\n",
    "        if (i == 1)\n",
    "            tr_idxs = tr_high\n",
    "        elseif (i == k)\n",
    "            tr_idxs = tr_low\n",
    "        else\n",
    "            tr_idxs = [tr_low ; tr_high ]\n",
    "        end\n",
    "        # @show i, val_idxs\n",
    "        # @show tr_low, tr_high\n",
    "        X_tr = X[idxs[tr_idxs],:]\n",
    "        y_tr = y[idxs[tr_idxs]]\n",
    "        \n",
    "        X_val = X[idxs[val_idxs],:]\n",
    "        y_val = y[idxs[val_idxs]]\n",
    "        \n",
    "        w = proxgrad(loss, regularizer, X_tr, y_tr; stepsize=stepsize) \n",
    "        ŷ_val = X_val * w\n",
    "        # @show size(y_val)\n",
    "        # @show size(ŷ_val)\n",
    "        error += error_metric(ŷ_val, y_val)\n",
    "    end\n",
    "    return error / k\n",
    "end\n",
    "\n",
    "# For each model in models, do k-fold cross validation and calculate the average error_metric\n",
    "# on the val set accross the k-folds.\n",
    "# Each model in model is a tuple of the form (featurizer, loss, regularizer, stepsize),\n",
    "# where a featurizer is a funciton that takes in a dataset and returns X,y. \n",
    "# Returns errors for each model, and the index of the best model\n",
    "function test_models(models, error_metric;k=10, dataset=train_dataset)\n",
    "    errors = []\n",
    "    for model in models\n",
    "        error = cross_val(model...,error_metric;k=k,dataset=dataset)\n",
    "        errors = [errors; error]\n",
    "    end\n",
    "    i = argmin(errors)\n",
    "    println(\"The best model is model \",i)\n",
    "    return errors,i\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "onehot"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_labels = [:carrier_lg, :carrier_low, :airportid_1, :airportid_2]\n",
    "cat_labels_sub = [:carrier_lg, :carrier_low]\n",
    "\n",
    "#Sets of all categories in a particular column\n",
    "cats_sets = [unique(dataset[:, label]) for label in cat_labels]\n",
    "cats_sets_sub = [unique(dataset[:, label]) for label in cat_labels_sub]\n",
    "\n",
    "\"Computes a onehot vector for every entry in column given a set of categories cats\"\n",
    "function onehot(column, cats=unique(column))\n",
    "    result = zeros(length(column), length(cats))\n",
    "    for i = 1:length(column)\n",
    "        for j =1:length(cats)\n",
    "            if column[i] === cats[j]\n",
    "                result[i, j] = 1\n",
    "            end    \n",
    "        end\n",
    "    end\n",
    "    result\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7-element Array{Symbol,1}:\n",
       " :when\n",
       " :nsmiles\n",
       " :passengers\n",
       " :large_ms\n",
       " :fare_lg\n",
       " :lf_ms\n",
       " :fare_low"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_real = [\n",
    "    :when, \n",
    "    :citymarketid_1, \n",
    "    :citymarketid_2,\n",
    "    :airportid_1,\n",
    "    :airportid_2,\n",
    "    :nsmiles,\n",
    "    :passengers,\n",
    "    :large_ms,\n",
    "    :fare_lg,\n",
    "    :lf_ms,\n",
    "    :fare_low\n",
    "]\n",
    "labels_real_sub = [\n",
    "    :when, \n",
    "    :nsmiles,\n",
    "    :passengers,\n",
    "    :large_ms,\n",
    "    :fare_lg,\n",
    "    :lf_ms,\n",
    "    :fare_low\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:10<00:00, 1.4 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.5 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.6 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.5 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.5 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.5 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.5 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.5 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.6 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.5 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.6 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.6 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.5 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.5 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.5 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.6 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.6 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.6 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.6 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.6 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.6 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.6 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.6 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.6 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.5 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.6 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.6 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.6 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.5 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.6 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.6 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.6 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.5 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.5 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.5 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.5 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.5 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.5 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.5 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.5 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.5 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.6 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.5 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.6 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.6 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.6 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.5 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.5 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.6 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.6 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.6 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.6 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.6 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.6 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.5 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.6 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.6 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.5 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.6 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.6 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.6 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.6 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.5 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.6 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.5 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.5 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.5 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.5 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.5 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.5 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.5 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.5 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.5 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.5 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.5 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:10<00:00, 1.4 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:10<00:00, 1.4 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:10<00:00, 1.4 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:10<00:00, 1.4 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:10<00:00, 1.4 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:10<00:00, 1.5 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:10<00:00, 1.4 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.5 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.6 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.5 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:10<00:00, 1.5 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.5 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.6 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.6 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.5 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.5 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.6 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.6 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.6 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.6 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:09<00:00, 1.5 it/s]\n",
      "The best model is model 70\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Any[6467.551888683022, 6462.756477567312, 6435.865820693679, 6568.462593980583, 6561.840064287084, 6493.668216515634, 6508.92465758739, 6533.031587033325, 6467.465767670953, 6452.796261167634  …  9398.488055603217, 9536.270182653117, 8664.510031780317, 8649.81556813873, 8684.61457987852, 8697.171090547248, 8619.209168865504, 8563.935453178123, 8618.224851341, 8644.394127064706], 70)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline featurizer\n",
    "function feats_0(dataset)\n",
    "    X = [dataset[:when] dataset[:airportid_1] dataset[:airportid_2] ones(size(dataset,1))]\n",
    "    y = dataset[:fare]\n",
    "    return X,y\n",
    "end\n",
    "\n",
    "# Only numeric features (treating airportid and cityid as numeric)\n",
    "function feats_1(dataset)\n",
    "    real_vals = convert(Matrix, dataset[labels_real])\n",
    "    X = hcat(real_vals, ones(size(dataset,1)))\n",
    "    y = dataset[:fare]\n",
    "    return X,y\n",
    "end\n",
    "\n",
    "# Numeric and categorical combined (treating airportid and cityid as numerical)\n",
    "function feats_2(dataset)\n",
    "    real_vals = convert(Matrix, dataset[labels_real])\n",
    "    cat_vals = hcat([onehot(dataset[:, cat_labels_sub[i]], cats_sets_sub[i]) for i in 1:size(cat_labels_sub, 1)]...)\n",
    "    X = hcat(cat_vals, real_vals, ones(size(dataset,1)))\n",
    "    y = dataset[:fare]\n",
    "    return X,y\n",
    "end\n",
    "\n",
    "# Numeric and categorical combined (treating airportid and cityid as categorical)\n",
    "function feats_3(dataset)\n",
    "    real_vals = convert(Matrix, dataset[labels_real_sub])\n",
    "    cat_vals = hcat([onehot(dataset[:, cat_labels[i]], cats_sets[i]) for i in 1:size(cat_labels, 1)]...)\n",
    "    X = hcat(cat_vals, real_vals, ones(size(dataset,1)))\n",
    "    y = dataset[:fare]\n",
    "    return X,y\n",
    "end\n",
    "\n",
    "MSE(L1,L2) = sum((L1.-L2).^2) / size(L1,1)\n",
    "\n",
    "models = [\n",
    "    (feats_0, 1/n_train*QuadLoss(), 0.25*QuadReg(), .1),\n",
    "    (feats_0, 1/n_train*QuadLoss(), 0.5 *QuadReg(), .1),\n",
    "    (feats_0, 1/n_train*QuadLoss(), 0.75*QuadReg(), .1),\n",
    "    (feats_0, 1/n_train*QuadLoss(), ZeroReg(), .1),\n",
    "    (feats_0, 1/n_train*QuadLoss(), 0.25*OneReg(), .1),\n",
    "    (feats_0, 1/n_train*QuadLoss(), 0.5 *OneReg(), .1),\n",
    "    (feats_0, 1/n_train*QuadLoss(), 0.75*OneReg(), .1),\n",
    "    (feats_0, 1/n_train*QuadLoss(), NonNegConstraint(), .1),\n",
    "    (feats_0, 1/n_train*L1Loss(), 0.25*QuadReg(), .1),\n",
    "    (feats_0, 1/n_train*L1Loss(), 0.5 *QuadReg(), .1),\n",
    "    (feats_0, 1/n_train*L1Loss(), 0.75*QuadReg(), .1),\n",
    "    (feats_0, 1/n_train*L1Loss(), ZeroReg(), .1),\n",
    "    (feats_0, 1/n_train*L1Loss(), 0.25*OneReg(), .1),\n",
    "    (feats_0, 1/n_train*L1Loss(), 0.5 *OneReg(), .1),\n",
    "    (feats_0, 1/n_train*L1Loss(), 0.75*OneReg(), .1),\n",
    "    (feats_0, 1/n_train*L1Loss(), NonNegConstraint(), .1),\n",
    "    (feats_0, 1/n_train*QuantileLoss(quantile=0.25), 0.25*QuadReg(), .1),\n",
    "    (feats_0, 1/n_train*QuantileLoss(quantile=0.25), 0.5 *QuadReg(), .1),\n",
    "    (feats_0, 1/n_train*QuantileLoss(quantile=0.25), 0.75*QuadReg(), .1),\n",
    "    (feats_0, 1/n_train*QuantileLoss(quantile=0.25), ZeroReg(), .1),\n",
    "    (feats_0, 1/n_train*QuantileLoss(quantile=0.25), 0.25*OneReg(), .1),\n",
    "    (feats_0, 1/n_train*QuantileLoss(quantile=0.25), 0.5 *OneReg(), .1),\n",
    "    (feats_0, 1/n_train*QuantileLoss(quantile=0.25), 0.75*OneReg(), .1),\n",
    "    (feats_0, 1/n_train*QuantileLoss(quantile=0.25), NonNegConstraint(), .1),\n",
    "    (feats_0, 1/n_train*QuantileLoss(quantile=0.75), 0.25*QuadReg(), .1),\n",
    "    (feats_0, 1/n_train*QuantileLoss(quantile=0.75), 0.5 *QuadReg(), .1),\n",
    "    (feats_0, 1/n_train*QuantileLoss(quantile=0.75), 0.75*QuadReg(), .1),\n",
    "    (feats_0, 1/n_train*QuantileLoss(quantile=0.75), ZeroReg(), .1),\n",
    "    (feats_0, 1/n_train*QuantileLoss(quantile=0.75), 0.25*OneReg(), .1),\n",
    "    (feats_0, 1/n_train*QuantileLoss(quantile=0.75), 0.5 *OneReg(), .1),\n",
    "    (feats_0, 1/n_train*QuantileLoss(quantile=0.75), 0.75*OneReg(), .1),\n",
    "    (feats_0, 1/n_train*QuantileLoss(quantile=0.75), NonNegConstraint(), .1),\n",
    "    (feats_0, 1/n_train*QuadLoss(), 0.25*QuadReg(), .5),\n",
    "    (feats_0, 1/n_train*QuadLoss(), 0.5 *QuadReg(), .5),\n",
    "    (feats_0, 1/n_train*QuadLoss(), 0.75*QuadReg(), .5),\n",
    "    (feats_0, 1/n_train*QuadLoss(), ZeroReg(), .5),\n",
    "    (feats_0, 1/n_train*QuadLoss(), 0.25*OneReg(), .5),\n",
    "    (feats_0, 1/n_train*QuadLoss(), 0.5 *OneReg(), .5),\n",
    "    (feats_0, 1/n_train*QuadLoss(), 0.75*OneReg(), .5),\n",
    "    (feats_0, 1/n_train*QuadLoss(), NonNegConstraint(), .5),\n",
    "    (feats_0, 1/n_train*L1Loss(), 0.25*QuadReg(), .5),\n",
    "    (feats_0, 1/n_train*L1Loss(), 0.5 *QuadReg(), .5),\n",
    "    (feats_0, 1/n_train*L1Loss(), 0.75*QuadReg(), .5),\n",
    "    (feats_0, 1/n_train*L1Loss(), ZeroReg(), .5),\n",
    "    (feats_0, 1/n_train*L1Loss(), 0.25*OneReg(), .5),\n",
    "    (feats_0, 1/n_train*L1Loss(), 0.5 *OneReg(), .5),\n",
    "    (feats_0, 1/n_train*L1Loss(), 0.75*OneReg(), .5),\n",
    "    (feats_0, 1/n_train*L1Loss(), NonNegConstraint(), .5),\n",
    "    (feats_0, 1/n_train*QuantileLoss(quantile=0.25), 0.25*QuadReg(), .5),\n",
    "    (feats_0, 1/n_train*QuantileLoss(quantile=0.25), 0.5 *QuadReg(), .5),\n",
    "    (feats_0, 1/n_train*QuantileLoss(quantile=0.25), 0.75*QuadReg(), .5),\n",
    "    (feats_0, 1/n_train*QuantileLoss(quantile=0.25), ZeroReg(), .5),\n",
    "    (feats_0, 1/n_train*QuantileLoss(quantile=0.25), 0.25*OneReg(), .5),\n",
    "    (feats_0, 1/n_train*QuantileLoss(quantile=0.25), 0.5 *OneReg(), .5),\n",
    "    (feats_0, 1/n_train*QuantileLoss(quantile=0.25), 0.75*OneReg(), .5),\n",
    "    (feats_0, 1/n_train*QuantileLoss(quantile=0.25), NonNegConstraint(), .5),\n",
    "    (feats_0, 1/n_train*QuantileLoss(quantile=0.75), 0.25*QuadReg(), .5),\n",
    "    (feats_0, 1/n_train*QuantileLoss(quantile=0.75), 0.5 *QuadReg(), .5),\n",
    "    (feats_0, 1/n_train*QuantileLoss(quantile=0.75), 0.75*QuadReg(), .5),\n",
    "    (feats_0, 1/n_train*QuantileLoss(quantile=0.75), ZeroReg(), .5),\n",
    "    (feats_0, 1/n_train*QuantileLoss(quantile=0.75), 0.25*OneReg(), .5),\n",
    "    (feats_0, 1/n_train*QuantileLoss(quantile=0.75), 0.5 *OneReg(), .5),\n",
    "    (feats_0, 1/n_train*QuantileLoss(quantile=0.75), 0.75*OneReg(), .5),\n",
    "    (feats_0, 1/n_train*QuantileLoss(quantile=0.75), NonNegConstraint(), .5),\n",
    "    (feats_0, 1/n_train*QuadLoss(), 0.25*QuadReg(), .9),\n",
    "    (feats_0, 1/n_train*QuadLoss(), 0.5 *QuadReg(), .9),\n",
    "    (feats_0, 1/n_train*QuadLoss(), 0.75*QuadReg(), .9),\n",
    "    (feats_0, 1/n_train*QuadLoss(), ZeroReg(), .9),\n",
    "    (feats_0, 1/n_train*QuadLoss(), 0.25*OneReg(), .9),\n",
    "    (feats_0, 1/n_train*QuadLoss(), 0.5 *OneReg(), .9), #best model for baseline features\n",
    "    (feats_0, 1/n_train*QuadLoss(), 0.75*OneReg(), .9),\n",
    "    (feats_0, 1/n_train*QuadLoss(), NonNegConstraint(), .9),\n",
    "    (feats_0, 1/n_train*L1Loss(), 0.25*QuadReg(), .9),\n",
    "    (feats_0, 1/n_train*L1Loss(), 0.5 *QuadReg(), .9),\n",
    "    (feats_0, 1/n_train*L1Loss(), 0.75*QuadReg(), .9),\n",
    "    (feats_0, 1/n_train*L1Loss(), ZeroReg(), .9),\n",
    "    (feats_0, 1/n_train*L1Loss(), 0.25*OneReg(), .9),\n",
    "    (feats_0, 1/n_train*L1Loss(), 0.5 *OneReg(), .9),\n",
    "    (feats_0, 1/n_train*L1Loss(), 0.75*OneReg(), .9),\n",
    "    (feats_0, 1/n_train*L1Loss(), NonNegConstraint(), .9),\n",
    "    (feats_0, 1/n_train*QuantileLoss(quantile=0.25), 0.25*QuadReg(), .9),\n",
    "    (feats_0, 1/n_train*QuantileLoss(quantile=0.25), 0.5 *QuadReg(), .9),\n",
    "    (feats_0, 1/n_train*QuantileLoss(quantile=0.25), 0.75*QuadReg(), .9),\n",
    "    (feats_0, 1/n_train*QuantileLoss(quantile=0.25), ZeroReg(), .9),\n",
    "    (feats_0, 1/n_train*QuantileLoss(quantile=0.25), 0.25*OneReg(), .9),\n",
    "    (feats_0, 1/n_train*QuantileLoss(quantile=0.25), 0.5 *OneReg(), .9),\n",
    "    (feats_0, 1/n_train*QuantileLoss(quantile=0.25), 0.75*OneReg(), .9),\n",
    "    (feats_0, 1/n_train*QuantileLoss(quantile=0.25), NonNegConstraint(), .9),\n",
    "    (feats_0, 1/n_train*QuantileLoss(quantile=0.75), 0.25*QuadReg(), .9),\n",
    "    (feats_0, 1/n_train*QuantileLoss(quantile=0.75), 0.5 *QuadReg(), .9),\n",
    "    (feats_0, 1/n_train*QuantileLoss(quantile=0.75), 0.75*QuadReg(), .9),\n",
    "    (feats_0, 1/n_train*QuantileLoss(quantile=0.75), ZeroReg(), .9),\n",
    "    (feats_0, 1/n_train*QuantileLoss(quantile=0.75), 0.25*OneReg(), .9),\n",
    "    (feats_0, 1/n_train*QuantileLoss(quantile=0.75), 0.5 *OneReg(), .9),\n",
    "    (feats_0, 1/n_train*QuantileLoss(quantile=0.75), 0.75*OneReg(), .9),\n",
    "    (feats_0, 1/n_train*QuantileLoss(quantile=0.75), NonNegConstraint(), .9)\n",
    "]\n",
    "\n",
    "errors,i = test_models(models,MSE;k=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:14<00:00, 1.0 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:14<00:00, 1.0 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.0 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.0 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:12<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.0 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.0 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.0 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:14<00:00, 1.0 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:14<00:00, 1.0 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:14<00:00, 1.0 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:14<00:00, 1.0 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:14<00:00, 1.0 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:14<00:00, 1.0 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:14<00:00, 1.0 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [00:13<00:00, 1.1 it/s]\n",
      "The best model is model 71\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Any[6305.997252683987, 6271.462380781899, 6196.889099740755, 6309.750546766214, 6393.938412442872, 6182.636198861417, 6228.272514605144, 6223.233906102328, 6239.731865914617, 6518.447705105094  …  9183.119433804932, 9293.860659800637, 8327.582702670246, 8160.179336498955, 8138.5573060351035, 8104.240355711566, 8329.811487347273, 8026.637669137322, 8178.283158899549, 8114.71306059098], 71)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_1 = [\n",
    "    (feats_1, 1/n_train*QuadLoss(), 0.25*QuadReg(), .1),\n",
    "    (feats_1, 1/n_train*QuadLoss(), 0.5 *QuadReg(), .1),\n",
    "    (feats_1, 1/n_train*QuadLoss(), 0.75*QuadReg(), .1),\n",
    "    (feats_1, 1/n_train*QuadLoss(), ZeroReg(), .1),\n",
    "    (feats_1, 1/n_train*QuadLoss(), 0.25*OneReg(), .1),\n",
    "    (feats_1, 1/n_train*QuadLoss(), 0.5 *OneReg(), .1),\n",
    "    (feats_1, 1/n_train*QuadLoss(), 0.75*OneReg(), .1),\n",
    "    (feats_1, 1/n_train*QuadLoss(), NonNegConstraint(), .1),\n",
    "    (feats_1, 1/n_train*L1Loss(), 0.25*QuadReg(), .1),\n",
    "    (feats_1, 1/n_train*L1Loss(), 0.5 *QuadReg(), .1),\n",
    "    (feats_1, 1/n_train*L1Loss(), 0.75*QuadReg(), .1),\n",
    "    (feats_1, 1/n_train*L1Loss(), ZeroReg(), .1),\n",
    "    (feats_1, 1/n_train*L1Loss(), 0.25*OneReg(), .1),\n",
    "    (feats_1, 1/n_train*L1Loss(), 0.5 *OneReg(), .1),\n",
    "    (feats_1, 1/n_train*L1Loss(), 0.75*OneReg(), .1),\n",
    "    (feats_1, 1/n_train*L1Loss(), NonNegConstraint(), .1),\n",
    "    (feats_1, 1/n_train*QuantileLoss(quantile=0.25), 0.25*QuadReg(), .1),\n",
    "    (feats_1, 1/n_train*QuantileLoss(quantile=0.25), 0.5 *QuadReg(), .1),\n",
    "    (feats_1, 1/n_train*QuantileLoss(quantile=0.25), 0.75*QuadReg(), .1),\n",
    "    (feats_1, 1/n_train*QuantileLoss(quantile=0.25), ZeroReg(), .1),\n",
    "    (feats_1, 1/n_train*QuantileLoss(quantile=0.25), 0.25*OneReg(), .1),\n",
    "    (feats_1, 1/n_train*QuantileLoss(quantile=0.25), 0.5 *OneReg(), .1),\n",
    "    (feats_1, 1/n_train*QuantileLoss(quantile=0.25), 0.75*OneReg(), .1),\n",
    "    (feats_1, 1/n_train*QuantileLoss(quantile=0.25), NonNegConstraint(), .1),\n",
    "    (feats_1, 1/n_train*QuantileLoss(quantile=0.75), 0.25*QuadReg(), .1),\n",
    "    (feats_1, 1/n_train*QuantileLoss(quantile=0.75), 0.5 *QuadReg(), .1),\n",
    "    (feats_1, 1/n_train*QuantileLoss(quantile=0.75), 0.75*QuadReg(), .1),\n",
    "    (feats_1, 1/n_train*QuantileLoss(quantile=0.75), ZeroReg(), .1),\n",
    "    (feats_1, 1/n_train*QuantileLoss(quantile=0.75), 0.25*OneReg(), .1),\n",
    "    (feats_1, 1/n_train*QuantileLoss(quantile=0.75), 0.5 *OneReg(), .1),\n",
    "    (feats_1, 1/n_train*QuantileLoss(quantile=0.75), 0.75*OneReg(), .1),\n",
    "    (feats_1, 1/n_train*QuantileLoss(quantile=0.75), NonNegConstraint(), .1),\n",
    "    (feats_1, 1/n_train*QuadLoss(), 0.25*QuadReg(), .5),\n",
    "    (feats_1, 1/n_train*QuadLoss(), 0.5 *QuadReg(), .5),\n",
    "    (feats_1, 1/n_train*QuadLoss(), 0.75*QuadReg(), .5),\n",
    "    (feats_1, 1/n_train*QuadLoss(), ZeroReg(), .5),\n",
    "    (feats_1, 1/n_train*QuadLoss(), 0.25*OneReg(), .5),\n",
    "    (feats_1, 1/n_train*QuadLoss(), 0.5 *OneReg(), .5),\n",
    "    (feats_1, 1/n_train*QuadLoss(), 0.75*OneReg(), .5),\n",
    "    (feats_1, 1/n_train*QuadLoss(), NonNegConstraint(), .5),\n",
    "    (feats_1, 1/n_train*L1Loss(), 0.25*QuadReg(), .5),\n",
    "    (feats_1, 1/n_train*L1Loss(), 0.5 *QuadReg(), .5),\n",
    "    (feats_1, 1/n_train*L1Loss(), 0.75*QuadReg(), .5),\n",
    "    (feats_1, 1/n_train*L1Loss(), ZeroReg(), .5),\n",
    "    (feats_1, 1/n_train*L1Loss(), 0.25*OneReg(), .5),\n",
    "    (feats_1, 1/n_train*L1Loss(), 0.5 *OneReg(), .5),\n",
    "    (feats_1, 1/n_train*L1Loss(), 0.75*OneReg(), .5),\n",
    "    (feats_1, 1/n_train*L1Loss(), NonNegConstraint(), .5),\n",
    "    (feats_1, 1/n_train*QuantileLoss(quantile=0.25), 0.25*QuadReg(), .5),\n",
    "    (feats_1, 1/n_train*QuantileLoss(quantile=0.25), 0.5 *QuadReg(), .5),\n",
    "    (feats_1, 1/n_train*QuantileLoss(quantile=0.25), 0.75*QuadReg(), .5),\n",
    "    (feats_1, 1/n_train*QuantileLoss(quantile=0.25), ZeroReg(), .5),\n",
    "    (feats_1, 1/n_train*QuantileLoss(quantile=0.25), 0.25*OneReg(), .5),\n",
    "    (feats_1, 1/n_train*QuantileLoss(quantile=0.25), 0.5 *OneReg(), .5),\n",
    "    (feats_1, 1/n_train*QuantileLoss(quantile=0.25), 0.75*OneReg(), .5),\n",
    "    (feats_1, 1/n_train*QuantileLoss(quantile=0.25), NonNegConstraint(), .5),\n",
    "    (feats_1, 1/n_train*QuantileLoss(quantile=0.75), 0.25*QuadReg(), .5),\n",
    "    (feats_1, 1/n_train*QuantileLoss(quantile=0.75), 0.5 *QuadReg(), .5),\n",
    "    (feats_1, 1/n_train*QuantileLoss(quantile=0.75), 0.75*QuadReg(), .5),\n",
    "    (feats_1, 1/n_train*QuantileLoss(quantile=0.75), ZeroReg(), .5),\n",
    "    (feats_1, 1/n_train*QuantileLoss(quantile=0.75), 0.25*OneReg(), .5),\n",
    "    (feats_1, 1/n_train*QuantileLoss(quantile=0.75), 0.5 *OneReg(), .5),\n",
    "    (feats_1, 1/n_train*QuantileLoss(quantile=0.75), 0.75*OneReg(), .5),\n",
    "    (feats_1, 1/n_train*QuantileLoss(quantile=0.75), NonNegConstraint(), .5),\n",
    "    (feats_1, 1/n_train*QuadLoss(), 0.25*QuadReg(), .9),\n",
    "    (feats_1, 1/n_train*QuadLoss(), 0.5 *QuadReg(), .9),\n",
    "    (feats_1, 1/n_train*QuadLoss(), 0.75*QuadReg(), .9),\n",
    "    (feats_1, 1/n_train*QuadLoss(), ZeroReg(), .9),\n",
    "    (feats_1, 1/n_train*QuadLoss(), 0.25*OneReg(), .9),\n",
    "    (feats_1, 1/n_train*QuadLoss(), 0.5 *OneReg(), .9),\n",
    "    (feats_1, 1/n_train*QuadLoss(), 0.75*OneReg(), .9), #best model out of feature set 1\n",
    "    (feats_1, 1/n_train*QuadLoss(), NonNegConstraint(), .9),\n",
    "    (feats_1, 1/n_train*L1Loss(), 0.25*QuadReg(), .9),\n",
    "    (feats_1, 1/n_train*L1Loss(), 0.5 *QuadReg(), .9),\n",
    "    (feats_1, 1/n_train*L1Loss(), 0.75*QuadReg(), .9),\n",
    "    (feats_1, 1/n_train*L1Loss(), ZeroReg(), .9),\n",
    "    (feats_1, 1/n_train*L1Loss(), 0.25*OneReg(), .9),\n",
    "    (feats_1, 1/n_train*L1Loss(), 0.5 *OneReg(), .9),\n",
    "    (feats_1, 1/n_train*L1Loss(), 0.75*OneReg(), .9),\n",
    "    (feats_1, 1/n_train*L1Loss(), NonNegConstraint(), .9),\n",
    "    (feats_1, 1/n_train*QuantileLoss(quantile=0.25), 0.25*QuadReg(), .9),\n",
    "    (feats_1, 1/n_train*QuantileLoss(quantile=0.25), 0.5 *QuadReg(), .9),\n",
    "    (feats_1, 1/n_train*QuantileLoss(quantile=0.25), 0.75*QuadReg(), .9),\n",
    "    (feats_1, 1/n_train*QuantileLoss(quantile=0.25), ZeroReg(), .9),\n",
    "    (feats_1, 1/n_train*QuantileLoss(quantile=0.25), 0.25*OneReg(), .9),\n",
    "    (feats_1, 1/n_train*QuantileLoss(quantile=0.25), 0.5 *OneReg(), .9),\n",
    "    (feats_1, 1/n_train*QuantileLoss(quantile=0.25), 0.75*OneReg(), .9),\n",
    "    (feats_1, 1/n_train*QuantileLoss(quantile=0.25), NonNegConstraint(), .9),\n",
    "    (feats_1, 1/n_train*QuantileLoss(quantile=0.75), 0.25*QuadReg(), .9),\n",
    "    (feats_1, 1/n_train*QuantileLoss(quantile=0.75), 0.5 *QuadReg(), .9),\n",
    "    (feats_1, 1/n_train*QuantileLoss(quantile=0.75), 0.75*QuadReg(), .9),\n",
    "    (feats_1, 1/n_train*QuantileLoss(quantile=0.75), ZeroReg(), .9),\n",
    "    (feats_1, 1/n_train*QuantileLoss(quantile=0.75), 0.25*OneReg(), .9),\n",
    "    (feats_1, 1/n_train*QuantileLoss(quantile=0.75), 0.5 *OneReg(), .9),\n",
    "    (feats_1, 1/n_train*QuantileLoss(quantile=0.75), 0.75*OneReg(), .9),\n",
    "    (feats_1, 1/n_train*QuantileLoss(quantile=0.75), NonNegConstraint(), .9),\n",
    "]\n",
    "errors,i = test_models(models_1,MSE;k=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:10<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:09<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:07<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:06<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:07<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:07<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:07<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:18<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:30<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:20<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:22<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:18<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:17<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:17<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:15<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:13<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:13<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:17<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:15<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:13<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:17<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:18<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:18<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:18<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:17<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:13<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:20<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:26<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:26<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:16<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:14<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:10<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:14<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:15<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:16<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:18<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:09<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:08<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:08<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:09<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:07<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:12<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:13<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:15<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:15<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:17<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:16<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:11<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:12<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:11<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:13<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:13<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:08<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:08<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:06<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:09<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:07<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:08<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:11<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:10<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:07<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:07<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:06<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:06<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:08<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:07<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:08<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:08<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:08<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:08<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:08<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:08<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:07<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:07<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:07<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:06<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:07<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:06<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:06<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:06<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:06<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:06<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:07<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:06<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:08<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:07<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:07<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:06<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:06<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:08<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:07<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:07<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:06<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:06<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:09<00:00, 0.2 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [01:06<00:00, 0.2 it/s]\n",
      "The best model is model 67\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Any[6266.201809375093, 6179.850179292898, 6299.418558854985, 6213.9229051641705, 6234.898159116057, 6228.07048011717, 6143.61458287267, 6267.433525759858, 6286.987083409578, 6436.177974610369  …  9325.803235350766, 9090.610732403255, 8082.05111424513, 8157.811159486968, 8196.09570750356, 8224.5759449218, 8101.630097003499, 8175.535267848258, 8202.601728304004, 8156.57629233738], 67)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_2 = [\n",
    "    (feats_2, 1/n_train*QuadLoss(), 0.25*QuadReg(), .1),\n",
    "    (feats_2, 1/n_train*QuadLoss(), 0.5 *QuadReg(), .1),\n",
    "    (feats_2, 1/n_train*QuadLoss(), 0.75*QuadReg(), .1),\n",
    "    (feats_2, 1/n_train*QuadLoss(), ZeroReg(), .1),\n",
    "    (feats_2, 1/n_train*QuadLoss(), 0.25*OneReg(), .1),\n",
    "    (feats_2, 1/n_train*QuadLoss(), 0.5 *OneReg(), .1),\n",
    "    (feats_2, 1/n_train*QuadLoss(), 0.75*OneReg(), .1),\n",
    "    (feats_2, 1/n_train*QuadLoss(), NonNegConstraint(), .1),\n",
    "    (feats_2, 1/n_train*L1Loss(), 0.25*QuadReg(), .1),\n",
    "    (feats_2, 1/n_train*L1Loss(), 0.5 *QuadReg(), .1),\n",
    "    (feats_2, 1/n_train*L1Loss(), 0.75*QuadReg(), .1),\n",
    "    (feats_2, 1/n_train*L1Loss(), ZeroReg(), .1),\n",
    "    (feats_2, 1/n_train*L1Loss(), 0.25*OneReg(), .1),\n",
    "    (feats_2, 1/n_train*L1Loss(), 0.5 *OneReg(), .1),\n",
    "    (feats_2, 1/n_train*L1Loss(), 0.75*OneReg(), .1),\n",
    "    (feats_2, 1/n_train*L1Loss(), NonNegConstraint(), .1),\n",
    "    (feats_2, 1/n_train*QuantileLoss(quantile=0.25), 0.25*QuadReg(), .1),\n",
    "    (feats_2, 1/n_train*QuantileLoss(quantile=0.25), 0.5 *QuadReg(), .1),\n",
    "    (feats_2, 1/n_train*QuantileLoss(quantile=0.25), 0.75*QuadReg(), .1),\n",
    "    (feats_2, 1/n_train*QuantileLoss(quantile=0.25), ZeroReg(), .1),\n",
    "    (feats_2, 1/n_train*QuantileLoss(quantile=0.25), 0.25*OneReg(), .1),\n",
    "    (feats_2, 1/n_train*QuantileLoss(quantile=0.25), 0.5 *OneReg(), .1),\n",
    "    (feats_2, 1/n_train*QuantileLoss(quantile=0.25), 0.75*OneReg(), .1),\n",
    "    (feats_2, 1/n_train*QuantileLoss(quantile=0.25), NonNegConstraint(), .1),\n",
    "    (feats_2, 1/n_train*QuantileLoss(quantile=0.75), 0.25*QuadReg(), .1),\n",
    "    (feats_2, 1/n_train*QuantileLoss(quantile=0.75), 0.5 *QuadReg(), .1),\n",
    "    (feats_2, 1/n_train*QuantileLoss(quantile=0.75), 0.75*QuadReg(), .1),\n",
    "    (feats_2, 1/n_train*QuantileLoss(quantile=0.75), ZeroReg(), .1),\n",
    "    (feats_2, 1/n_train*QuantileLoss(quantile=0.75), 0.25*OneReg(), .1),\n",
    "    (feats_2, 1/n_train*QuantileLoss(quantile=0.75), 0.5 *OneReg(), .1),\n",
    "    (feats_2, 1/n_train*QuantileLoss(quantile=0.75), 0.75*OneReg(), .1),\n",
    "    (feats_2, 1/n_train*QuantileLoss(quantile=0.75), NonNegConstraint(), .1),\n",
    "    (feats_2, 1/n_train*QuadLoss(), 0.25*QuadReg(), .5),\n",
    "    (feats_2, 1/n_train*QuadLoss(), 0.5 *QuadReg(), .5),\n",
    "    (feats_2, 1/n_train*QuadLoss(), 0.75*QuadReg(), .5),\n",
    "    (feats_2, 1/n_train*QuadLoss(), ZeroReg(), .5),\n",
    "    (feats_2, 1/n_train*QuadLoss(), 0.25*OneReg(), .5),\n",
    "    (feats_2, 1/n_train*QuadLoss(), 0.5 *OneReg(), .5),\n",
    "    (feats_2, 1/n_train*QuadLoss(), 0.75*OneReg(), .5),\n",
    "    (feats_2, 1/n_train*QuadLoss(), NonNegConstraint(), .5),\n",
    "    (feats_2, 1/n_train*L1Loss(), 0.25*QuadReg(), .5),\n",
    "    (feats_2, 1/n_train*L1Loss(), 0.5 *QuadReg(), .5),\n",
    "    (feats_2, 1/n_train*L1Loss(), 0.75*QuadReg(), .5),\n",
    "    (feats_2, 1/n_train*L1Loss(), ZeroReg(), .5),\n",
    "    (feats_2, 1/n_train*L1Loss(), 0.25*OneReg(), .5),\n",
    "    (feats_2, 1/n_train*L1Loss(), 0.5 *OneReg(), .5),\n",
    "    (feats_2, 1/n_train*L1Loss(), 0.75*OneReg(), .5),\n",
    "    (feats_2, 1/n_train*L1Loss(), NonNegConstraint(), .5),\n",
    "    (feats_2, 1/n_train*QuantileLoss(quantile=0.25), 0.25*QuadReg(), .5),\n",
    "    (feats_2, 1/n_train*QuantileLoss(quantile=0.25), 0.5 *QuadReg(), .5),\n",
    "    (feats_2, 1/n_train*QuantileLoss(quantile=0.25), 0.75*QuadReg(), .5),\n",
    "    (feats_2, 1/n_train*QuantileLoss(quantile=0.25), ZeroReg(), .5),\n",
    "    (feats_2, 1/n_train*QuantileLoss(quantile=0.25), 0.25*OneReg(), .5),\n",
    "    (feats_2, 1/n_train*QuantileLoss(quantile=0.25), 0.5 *OneReg(), .5),\n",
    "    (feats_2, 1/n_train*QuantileLoss(quantile=0.25), 0.75*OneReg(), .5),\n",
    "    (feats_2, 1/n_train*QuantileLoss(quantile=0.25), NonNegConstraint(), .5),\n",
    "    (feats_2, 1/n_train*QuantileLoss(quantile=0.75), 0.25*QuadReg(), .5),\n",
    "    (feats_2, 1/n_train*QuantileLoss(quantile=0.75), 0.5 *QuadReg(), .5),\n",
    "    (feats_2, 1/n_train*QuantileLoss(quantile=0.75), 0.75*QuadReg(), .5),\n",
    "    (feats_2, 1/n_train*QuantileLoss(quantile=0.75), ZeroReg(), .5),\n",
    "    (feats_2, 1/n_train*QuantileLoss(quantile=0.75), 0.25*OneReg(), .5),\n",
    "    (feats_2, 1/n_train*QuantileLoss(quantile=0.75), 0.5 *OneReg(), .5),\n",
    "    (feats_2, 1/n_train*QuantileLoss(quantile=0.75), 0.75*OneReg(), .5),\n",
    "    (feats_2, 1/n_train*QuantileLoss(quantile=0.75), NonNegConstraint(), .5),\n",
    "    (feats_2, 1/n_train*QuadLoss(), 0.25*QuadReg(), .9),\n",
    "    (feats_2, 1/n_train*QuadLoss(), 0.5 *QuadReg(), .9),\n",
    "    (feats_2, 1/n_train*QuadLoss(), 0.75*QuadReg(), .9),\n",
    "    (feats_2, 1/n_train*QuadLoss(), ZeroReg(), .9),\n",
    "    (feats_2, 1/n_train*QuadLoss(), 0.25*OneReg(), .9),\n",
    "    (feats_2, 1/n_train*QuadLoss(), 0.5 *OneReg(), .9),\n",
    "    (feats_2, 1/n_train*QuadLoss(), 0.75*OneReg(), .9), #best model out of feature set 1\n",
    "    (feats_2, 1/n_train*QuadLoss(), NonNegConstraint(), .9),\n",
    "    (feats_2, 1/n_train*L1Loss(), 0.25*QuadReg(), .9),\n",
    "    (feats_2, 1/n_train*L1Loss(), 0.5 *QuadReg(), .9),\n",
    "    (feats_2, 1/n_train*L1Loss(), 0.75*QuadReg(), .9),\n",
    "    (feats_2, 1/n_train*L1Loss(), ZeroReg(), .9),\n",
    "    (feats_2, 1/n_train*L1Loss(), 0.25*OneReg(), .9),\n",
    "    (feats_2, 1/n_train*L1Loss(), 0.5 *OneReg(), .9),\n",
    "    (feats_2, 1/n_train*L1Loss(), 0.75*OneReg(), .9),\n",
    "    (feats_2, 1/n_train*L1Loss(), NonNegConstraint(), .9),\n",
    "    (feats_2, 1/n_train*QuantileLoss(quantile=0.25), 0.25*QuadReg(), .9),\n",
    "    (feats_2, 1/n_train*QuantileLoss(quantile=0.25), 0.5 *QuadReg(), .9),\n",
    "    (feats_2, 1/n_train*QuantileLoss(quantile=0.25), 0.75*QuadReg(), .9),\n",
    "    (feats_2, 1/n_train*QuantileLoss(quantile=0.25), ZeroReg(), .9),\n",
    "    (feats_2, 1/n_train*QuantileLoss(quantile=0.25), 0.25*OneReg(), .9),\n",
    "    (feats_2, 1/n_train*QuantileLoss(quantile=0.25), 0.5 *OneReg(), .9),\n",
    "    (feats_2, 1/n_train*QuantileLoss(quantile=0.25), 0.75*OneReg(), .9),\n",
    "    (feats_2, 1/n_train*QuantileLoss(quantile=0.25), NonNegConstraint(), .9),\n",
    "    (feats_2, 1/n_train*QuantileLoss(quantile=0.75), 0.25*QuadReg(), .9),\n",
    "    (feats_2, 1/n_train*QuantileLoss(quantile=0.75), 0.5 *QuadReg(), .9),\n",
    "    (feats_2, 1/n_train*QuantileLoss(quantile=0.75), 0.75*QuadReg(), .9),\n",
    "    (feats_2, 1/n_train*QuantileLoss(quantile=0.75), ZeroReg(), .9),\n",
    "    (feats_2, 1/n_train*QuantileLoss(quantile=0.75), 0.25*OneReg(), .9),\n",
    "    (feats_2, 1/n_train*QuantileLoss(quantile=0.75), 0.5 *OneReg(), .9),\n",
    "    (feats_2, 1/n_train*QuantileLoss(quantile=0.75), 0.75*OneReg(), .9),\n",
    "    (feats_2, 1/n_train*QuantileLoss(quantile=0.75), NonNegConstraint(), .9)\n",
    "]\n",
    "errors,i = test_models(models_2,MSE;k=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0%┣██████████████████████████████████████████┫ 15/15 [03:17<00:00, 0.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [03:22<00:00, 0.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [03:11<00:00, 0.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [03:10<00:00, 0.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [03:11<00:00, 0.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [03:10<00:00, 0.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [03:11<00:00, 0.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [03:10<00:00, 0.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [03:07<00:00, 0.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [03:07<00:00, 0.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [03:09<00:00, 0.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [03:09<00:00, 0.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [03:10<00:00, 0.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [03:23<00:00, 0.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [03:34<00:00, 0.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [03:18<00:00, 0.1 it/s]\n",
      "The best model is model 16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Any[3357.2838335817164, 3295.2864577773826, 3287.225881237891, 3275.137054469704, 3242.045020490456, 3249.7651486432164, 3278.1923444564723, 3369.799247315818, 3465.022985453251, 3447.767046742311, 3416.937395629453, 3429.8284889978268, 3492.204392651664, 3355.8706872047155, 3403.0683547048525, 3084.937956801807], 16)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_3 = [\n",
    "    (feats_3, 1/n_train*QuadLoss(), 0.25*QuadReg(), .1),\n",
    "    (feats_3, 1/n_train*QuadLoss(), 0.5 *QuadReg(), .1),\n",
    "    (feats_3, 1/n_train*QuadLoss(), 0.75*QuadReg(), .1),\n",
    "    (feats_3, 1/n_train*QuadLoss(), ZeroReg(), .1),\n",
    "    (feats_3, 1/n_train*QuadLoss(), 0.25*OneReg(), .1),\n",
    "    (feats_3, 1/n_train*QuadLoss(), 0.5 *OneReg(), .1),\n",
    "    (feats_3, 1/n_train*QuadLoss(), 0.75*OneReg(), .1),\n",
    "    (feats_3, 1/n_train*QuadLoss(), NonNegConstraint(), .1),\n",
    "    (feats_3, 1/n_train*L1Loss(), 0.25*QuadReg(), .1),\n",
    "    (feats_3, 1/n_train*L1Loss(), 0.5 *QuadReg(), .1),\n",
    "    (feats_3, 1/n_train*L1Loss(), 0.75*QuadReg(), .1),\n",
    "    (feats_3, 1/n_train*L1Loss(), ZeroReg(), .1),\n",
    "    (feats_3, 1/n_train*L1Loss(), 0.25*OneReg(), .1),\n",
    "    (feats_3, 1/n_train*L1Loss(), 0.5 *OneReg(), .1),\n",
    "    (feats_3, 1/n_train*L1Loss(), 0.75*OneReg(), .1),\n",
    "    (feats_3, 1/n_train*L1Loss(), NonNegConstraint(), .1)\n",
    "]\n",
    "errors,i = test_models(models_3,MSE;k=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can see here that feature set 3 has the lowest MSE (nearly 1/2 of the previous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0%┣██████████████████████████████████████████┫ 15/15 [03:20<00:00, 0.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [03:15<00:00, 0.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [03:06<00:00, 0.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [03:14<00:00, 0.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [03:16<00:00, 0.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [03:09<00:00, 0.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [03:07<00:00, 0.1 it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 15/15 [03:20<00:00, 0.1 it/s]\n",
      "The best model is model 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Any[3005.0165206460447, 3265.2619125606057, 3385.6306728762675, 3653.047618320855, 2995.360429684404, 3410.4861248677366, 3027.7771867129504, 3041.4758933270527], 5)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [\n",
    "    (feats_3, 1/n_train*L1Loss(), NonNegConstraint(), .8), \n",
    "    (feats_3, 1/n_train*L1Loss(), NonNegConstraint(), .7), \n",
    "    (feats_3, 1/n_train*L1Loss(), NonNegConstraint(), .6), \n",
    "    (feats_3, 1/n_train*L1Loss(), NonNegConstraint(), .5), \n",
    "    (feats_3, 1/n_train*L1Loss(), NonNegConstraint(), .4), \n",
    "    (feats_3, 1/n_train*L1Loss(), NonNegConstraint(), .3), \n",
    "    (feats_3, 1/n_train*L1Loss(), NonNegConstraint(), .2), \n",
    "    (feats_3, 1/n_train*L1Loss(), NonNegConstraint(), .1)\n",
    "]\n",
    "errors,i = test_models(models,MSE;k=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0%┣████████████████████████████████████████████┫ 5/5 [00:59<00:00, 0.1 it/s]\n",
      "100.0%┣████████████████████████████████████████████┫ 5/5 [00:58<00:00, 0.1 it/s]\n",
      "100.0%┣████████████████████████████████████████████┫ 5/5 [00:57<00:00, 0.1 it/s]\n",
      "100.0%┣████████████████████████████████████████████┫ 5/5 [00:56<00:00, 0.1 it/s]\n",
      "100.0%┣████████████████████████████████████████████┫ 5/5 [00:56<00:00, 0.1 it/s]\n",
      "100.0%┣████████████████████████████████████████████┫ 5/5 [00:56<00:00, 0.1 it/s]\n",
      "100.0%┣████████████████████████████████████████████┫ 5/5 [00:56<00:00, 0.1 it/s]\n",
      "100.0%┣████████████████████████████████████████████┫ 5/5 [00:55<00:00, 0.1 it/s]\n",
      "100.0%┣████████████████████████████████████████████┫ 5/5 [00:56<00:00, 0.1 it/s]\n",
      "100.0%┣████████████████████████████████████████████┫ 5/5 [00:56<00:00, 0.1 it/s]\n",
      "100.0%┣████████████████████████████████████████████┫ 5/5 [00:57<00:00, 0.1 it/s]\n",
      "100.0%┣████████████████████████████████████████████┫ 5/5 [00:58<00:00, 0.1 it/s]\n",
      "100.0%┣████████████████████████████████████████████┫ 5/5 [00:57<00:00, 0.1 it/s]\n",
      "100.0%┣████████████████████████████████████████████┫ 5/5 [00:54<00:00, 0.1 it/s]\n",
      "100.0%┣████████████████████████████████████████████┫ 5/5 [00:54<00:00, 0.1 it/s]\n",
      "100.0%┣████████████████████████████████████████████┫ 5/5 [00:54<00:00, 0.1 it/s]\n",
      "100.0%┣████████████████████████████████████████████┫ 5/5 [00:54<00:00, 0.1 it/s]\n",
      "100.0%┣████████████████████████████████████████████┫ 5/5 [00:55<00:00, 0.1 it/s]\n",
      "100.0%┣████████████████████████████████████████████┫ 5/5 [00:58<00:00, 0.1 it/s]\n",
      "100.0%┣████████████████████████████████████████████┫ 5/5 [01:00<00:00, 0.1 it/s]\n",
      "100.0%┣████████████████████████████████████████████┫ 5/5 [01:00<00:00, 0.1 it/s]\n",
      "100.0%┣████████████████████████████████████████████┫ 5/5 [01:00<00:00, 0.1 it/s]\n",
      "100.0%┣████████████████████████████████████████████┫ 5/5 [00:54<00:00, 0.1 it/s]\n",
      "100.0%┣████████████████████████████████████████████┫ 5/5 [00:54<00:00, 0.1 it/s]\n",
      "100.0%┣████████████████████████████████████████████┫ 5/5 [00:57<00:00, 0.1 it/s]\n",
      "100.0%┣████████████████████████████████████████████┫ 5/5 [01:05<00:00, 0.1 it/s]\n",
      "100.0%┣████████████████████████████████████████████┫ 5/5 [01:01<00:00, 0.1 it/s]\n",
      "100.0%┣████████████████████████████████████████████┫ 5/5 [01:00<00:00, 0.1 it/s]\n",
      "100.0%┣████████████████████████████████████████████┫ 5/5 [00:58<00:00, 0.1 it/s]\n",
      "100.0%┣████████████████████████████████████████████┫ 5/5 [00:58<00:00, 0.1 it/s]\n",
      "100.0%┣████████████████████████████████████████████┫ 5/5 [00:58<00:00, 0.1 it/s]\n",
      "100.0%┣████████████████████████████████████████████┫ 5/5 [00:58<00:00, 0.1 it/s]\n",
      "The best model is model 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Any[2800.1743285934285, 2789.8405458206967, 2761.3771345334217, 2816.478150168958, 2785.5399614826356, 2792.938879470165, 2803.255684187071, 2846.635443854345, 3168.7968558040384, 3104.5718749288612  …  5264.390079625461, 5302.852204418142, 4147.420116496212, 4121.741788289379, 4144.208322418345, 4273.109026539858, 4161.2087032088075, 4327.197801428348, 4200.065690369818, 4392.601289272541], 3)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [\n",
    "    (feats_3, 1/n_train*QuadLoss(), 0.25*QuadReg(), .4),\n",
    "    (feats_3, 1/n_train*QuadLoss(), 0.5 *QuadReg(), .4),\n",
    "    (feats_3, 1/n_train*QuadLoss(), 0.75*QuadReg(), .4),\n",
    "    (feats_3, 1/n_train*QuadLoss(), ZeroReg(), .4),\n",
    "    (feats_3, 1/n_train*QuadLoss(), 0.25*OneReg(), .4),\n",
    "    (feats_3, 1/n_train*QuadLoss(), 0.5 *OneReg(), .4),\n",
    "    (feats_3, 1/n_train*QuadLoss(), 0.75*OneReg(), .4),\n",
    "    (feats_3, 1/n_train*QuadLoss(), NonNegConstraint(), .4),\n",
    "    (feats_3, 1/n_train*L1Loss(), 0.25*QuadReg(), .4),\n",
    "    (feats_3, 1/n_train*L1Loss(), 0.5 *QuadReg(), .4),\n",
    "    (feats_3, 1/n_train*L1Loss(), 0.75*QuadReg(), .4),\n",
    "    (feats_3, 1/n_train*L1Loss(), ZeroReg(), .4),\n",
    "    (feats_3, 1/n_train*L1Loss(), 0.25*OneReg(), .4),\n",
    "    (feats_3, 1/n_train*L1Loss(), 0.5 *OneReg(), .4),\n",
    "    (feats_3, 1/n_train*L1Loss(), 0.75*OneReg(), .4),\n",
    "    (feats_3, 1/n_train*L1Loss(), NonNegConstraint(), .4), #best model from above\n",
    "    (feats_3, 1/n_train*QuantileLoss(quantile=0.25), 0.25*QuadReg(), .4),\n",
    "    (feats_3, 1/n_train*QuantileLoss(quantile=0.25), 0.5 *QuadReg(), .4),\n",
    "    (feats_3, 1/n_train*QuantileLoss(quantile=0.25), 0.75*QuadReg(), .4),\n",
    "    (feats_3, 1/n_train*QuantileLoss(quantile=0.25), ZeroReg(), .4),\n",
    "    (feats_3, 1/n_train*QuantileLoss(quantile=0.25), 0.25*OneReg(), .4),\n",
    "    (feats_3, 1/n_train*QuantileLoss(quantile=0.25), 0.5 *OneReg(), .4),\n",
    "    (feats_3, 1/n_train*QuantileLoss(quantile=0.25), 0.75*OneReg(), .4),\n",
    "    (feats_3, 1/n_train*QuantileLoss(quantile=0.25), NonNegConstraint(), .4),\n",
    "    (feats_3, 1/n_train*QuantileLoss(quantile=0.75), 0.25*QuadReg(), .4),\n",
    "    (feats_3, 1/n_train*QuantileLoss(quantile=0.75), 0.5 *QuadReg(), .4),\n",
    "    (feats_3, 1/n_train*QuantileLoss(quantile=0.75), 0.75*QuadReg(), .4),\n",
    "    (feats_3, 1/n_train*QuantileLoss(quantile=0.75), ZeroReg(), .4),\n",
    "    (feats_3, 1/n_train*QuantileLoss(quantile=0.75), 0.25*OneReg(), .4),\n",
    "    (feats_3, 1/n_train*QuantileLoss(quantile=0.75), 0.5 *OneReg(), .4),\n",
    "    (feats_3, 1/n_train*QuantileLoss(quantile=0.75), 0.75*OneReg(), .4),\n",
    "    (feats_3, 1/n_train*QuantileLoss(quantile=0.75), NonNegConstraint(), .4),\n",
    "\n",
    "    \n",
    "    \n",
    "]\n",
    "errors,i = test_models(models,MSE;k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0%┣████████████████████████████████████████████┫ 5/5 [01:00<00:00, 0.1 it/s]\n",
      "100.0%┣████████████████████████████████████████████┫ 5/5 [01:00<00:00, 0.1 it/s]\n",
      "100.0%┣████████████████████████████████████████████┫ 5/5 [01:11<00:00, 0.1 it/s]\n",
      "100.0%┣████████████████████████████████████████████┫ 5/5 [01:01<00:00, 0.1 it/s]\n",
      "100.0%┣████████████████████████████████████████████┫ 5/5 [01:08<00:00, 0.1 it/s]\n",
      "100.0%┣████████████████████████████████████████████┫ 5/5 [01:01<00:00, 0.1 it/s]\n",
      "100.0%┣████████████████████████████████████████████┫ 5/5 [01:00<00:00, 0.1 it/s]\n",
      "100.0%┣████████████████████████████████████████████┫ 5/5 [01:02<00:00, 0.1 it/s]\n",
      "100.0%┣████████████████████████████████████████████┫ 5/5 [01:15<00:00, 0.1 it/s]\n",
      "100.0%┣████████████████████████████████████████████┫ 5/5 [01:05<00:00, 0.1 it/s]\n",
      "The best model is model 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Any[2884.3633978625353, 2786.7439862294805, 2806.030629960462, 2754.6959239578186, 2810.143786895092, 2812.113841355829, 2799.146681333407, 2814.2536251820316, 2766.1147604900643, 2824.4815213021575], 4)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [\n",
    "    (feats_3, 1/n_train*QuadLoss(), 0.1*QuadReg(), .4),\n",
    "    (feats_3, 1/n_train*QuadLoss(), 0.2*QuadReg(), .4),\n",
    "    (feats_3, 1/n_train*QuadLoss(), 0.3*QuadReg(), .4),\n",
    "    (feats_3, 1/n_train*QuadLoss(), 0.4*QuadReg(), .4),\n",
    "    (feats_3, 1/n_train*QuadLoss(), 0.5*QuadReg(), .4),\n",
    "    (feats_3, 1/n_train*QuadLoss(), 0.6*QuadReg(), .4),\n",
    "    (feats_3, 1/n_train*QuadLoss(), 0.7*QuadReg(), .4),\n",
    "    (feats_3, 1/n_train*QuadLoss(), 0.75*QuadReg(), .4),\n",
    "    (feats_3, 1/n_train*QuadLoss(), 0.8*QuadReg(), .4),\n",
    "    (feats_3, 1/n_train*QuadLoss(), 0.9*QuadReg(), .4),\n",
    "]\n",
    "errors,i = test_models(models,MSE;k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From this analysis, we can see that Feature Set 3 with Quadratic Loss and Regualarization, that gives the best model. We can tweak the lambda and learning rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.5.1",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
